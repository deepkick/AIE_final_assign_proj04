import streamlit as st
import pandas as pd
import openai
import os
from sklearn.cluster import KMeans
from sklearn.preprocessing import normalize
import numpy as np

st.set_page_config(
    page_title="è¬›ç¾©ã®è³ªç–‘å¿œç­”ã¾ã¨ã‚ã‚¢ãƒ—ãƒª : AIE Proj 04", layout="centered"
)
st.title("ğŸ“š è¬›ç¾©ã®è³ªç–‘å¿œç­”ã¾ã¨ã‚ã‚¢ãƒ—ãƒª : AIE Proj 04")

# Streamlit Cloud Secrets ã‹ã‚‰ OpenAI APIã‚­ãƒ¼ã‚’å–å¾—
openai_api_key = st.secrets["openai_api_key"]

# OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆopenai>=1.0.0å¯¾å¿œï¼‰
client = openai.OpenAI(api_key=openai_api_key)

# ã‚¯ãƒ©ã‚¹ã‚¿æ•°ã®æŒ‡å®š
num_clusters = st.slider("ã‚¯ãƒ©ã‚¹ã‚¿æ•°ï¼ˆKMeansï¼‰", min_value=2, max_value=20, value=5)

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_file = st.file_uploader(
    "ğŸ“¤ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆè³ªå•, å›ç­”ã®åˆ—ã‚’å«ã‚€ï¼‰", type=["csv"]
)

if uploaded_file:
    df = pd.read_csv(uploaded_file)

    if "è³ªå•" not in df.columns:
        st.error("'è³ªå•' ã¨ã„ã†åˆ—ãŒå¿…è¦ã§ã™ã€‚CSVã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    else:
        st.success(f"âœ… {len(df)} ä»¶ã®è³ªå•ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
        questions = df["è³ªå•"].dropna().tolist()

        # ãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼ˆOpenAIåŸ‹ã‚è¾¼ã¿ï¼‰
        with st.spinner("ğŸ’  OpenAIåŸ‹ã‚è¾¼ã¿ã‚’å–å¾—ä¸­..."):
            try:
                embeddings_response = client.embeddings.create(
                    model="text-embedding-ada-002", input=questions
                )
                vectors = np.array([e.embedding for e in embeddings_response.data])
            except Exception as e:
                st.error(f"åŸ‹ã‚è¾¼ã¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                st.stop()

        # KMeansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
        vectors_norm = normalize(vectors)
        kmeans = KMeans(n_clusters=num_clusters, random_state=42)
        labels = kmeans.fit_predict(vectors_norm)
        df["ã‚¯ãƒ©ã‚¹ã‚¿"] = labels

        st.success(
            f"âœ… {num_clusters} ã‚¯ãƒ©ã‚¹ã‚¿ã«åˆ†é¡ã—ã¾ã—ãŸã€‚å„ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã«è¦ç´„ã¨å›ç­”ã‚’ç”Ÿæˆã§ãã¾ã™ã€‚"
        )

        # ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã«è¦ç´„ã¨å›ç­”ç”Ÿæˆ
        for cluster_id in range(num_clusters):
            cluster_df = df[df["ã‚¯ãƒ©ã‚¹ã‚¿"] == cluster_id]
            cluster_questions = cluster_df["è³ªå•"].tolist()

            with st.expander(
                f"â–¶ï¸ ã‚¯ãƒ©ã‚¹ã‚¿ {cluster_id}ï¼š{len(cluster_questions)} ä»¶ã®è³ªå•"
            ):
                st.markdown("\n".join([f"- {q}" for q in cluster_questions]))

                if st.button(f"ğŸ§  ã‚¯ãƒ©ã‚¹ã‚¿ {cluster_id} ã®ä»£è¡¨è³ªå•ã‚’ç”Ÿæˆ"):
                    prompt = """
ä»¥ä¸‹ã®è³ªå•ã¯è¬›ç¾©ä¸­ã«å—ã‘ãŸä¼¼ãŸå†…å®¹ã®è³ªå•ã§ã™ã€‚ã“ã‚Œã‚‰ã‚’è¦ç´„ã—ã¦ã€ä»£è¡¨çš„ãª1ã¤ã®è³ªå•ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚
è³ªå•ä¸€è¦§ï¼š
"""
                    prompt += "\n".join([f"- {q}" for q in cluster_questions])
                    prompt += "\n\nä»£è¡¨è³ªå•ï¼š"

                    with st.spinner("GPTãŒä»£è¡¨è³ªå•ã‚’è¦ç´„ä¸­..."):
                        try:
                            response = client.chat.completions.create(
                                model="gpt-4",
                                messages=[
                                    {
                                        "role": "system",
                                        "content": "ã‚ãªãŸã¯è¦ªåˆ‡ã§è¦ç´„ãŒä¸Šæ‰‹ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚",
                                    },
                                    {"role": "user", "content": prompt},
                                ],
                                temperature=0.5,
                            )
                            summary_question = response.choices[
                                0
                            ].message.content.strip()
                            st.markdown(f"**ğŸ’¬ ä»£è¡¨è³ªå•ï¼š** {summary_question}")

                            if st.button(f"ğŸ’¡ ã‚¯ãƒ©ã‚¹ã‚¿ {cluster_id} ã®æ¨¡ç¯„å›ç­”ã‚’ç”Ÿæˆ"):
                                answer_prompt = f"ä»¥ä¸‹ã®è³ªå•ã«å¯¾ã—ã¦ã€è¬›ç¾©ã§ä½¿ãˆã‚‹æ¨¡ç¯„çš„ãªå›ç­”ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚\n\nè³ªå•ï¼š{summary_question}\n\nå›ç­”ï¼š"
                                with st.spinner("GPTãŒæ¨¡ç¯„å›ç­”ã‚’ç”Ÿæˆä¸­..."):
                                    try:
                                        answer_response = client.chat.completions.create(
                                            model="gpt-4",
                                            messages=[
                                                {
                                                    "role": "system",
                                                    "content": "ã‚ãªãŸã¯è¦ªåˆ‡ã§ã‚ã‹ã‚Šã‚„ã™ãèª¬æ˜ã§ãã‚‹è¬›ç¾©ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚",
                                                },
                                                {
                                                    "role": "user",
                                                    "content": answer_prompt,
                                                },
                                            ],
                                            temperature=0.7,
                                        )
                                        model_answer = answer_response.choices[
                                            0
                                        ].message.content.strip()
                                        st.markdown(
                                            f"**ğŸ“ æ¨¡ç¯„å›ç­”ï¼š**\n\n{model_answer}"
                                        )
                                    except Exception as e:
                                        st.error(
                                            f"æ¨¡ç¯„å›ç­”ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
                                        )
                        except Exception as e:
                            st.error(f"ä»£è¡¨è³ªå•ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
