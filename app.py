import streamlit as st
import pandas as pd
from openai import OpenAI
from sklearn.cluster import KMeans
from sklearn.preprocessing import normalize
import numpy as np

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Streamlit åŸºæœ¬è¨­å®š
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="è¬›ç¾©ã®è³ªç–‘å¿œç­”ã¾ã¨ã‚ã‚¢ãƒ—ãƒª : AIE Proj 04",
    layout="centered",
)
st.title("ğŸ“š è¬›ç¾©ã®è³ªç–‘å¿œç­”ã¾ã¨ã‚ã‚¢ãƒ—ãƒª : AIE Proj 04")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
openai_api_key = st.secrets["openai_api_key"]
client = OpenAI(api_key=openai_api_key)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# UIï¼šã‚¯ãƒ©ã‚¹ã‚¿æ•°ãƒ»ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
num_clusters = st.slider("ã‚¯ãƒ©ã‚¹ã‚¿æ•°ï¼ˆKMeansï¼‰", min_value=2, max_value=20, value=5)

uploaded_file = st.file_uploader(
    "ğŸ“¤ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆåˆ—: è³ªå•, å›ç­”ï¼‰", type=["csv"]
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if uploaded_file:
    df = pd.read_csv(uploaded_file)

    if "è³ªå•" not in df.columns:
        st.error("'è³ªå•' ã¨ã„ã†åˆ—ãŒå¿…è¦ã§ã™ã€‚CSVã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    st.success(f"âœ… {len(df)} ä»¶ã®è³ªå•ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")

    questions = df["è³ªå•"].dropna().tolist()

    # -- OpenAI Embeddings --------------------------------------------------
    with st.spinner("ğŸ’  OpenAI åŸ‹ã‚è¾¼ã¿ã‚’å–å¾—ä¸­..."):
        try:
            embeddings_response = client.embeddings.create(
                model="text-embedding-ada-002",
                input=questions,
            )
            vectors = np.array([e.embedding for e in embeddings_response.data])
        except Exception as e:
            st.error(f"åŸ‹ã‚è¾¼ã¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            st.stop()

    # -- KMeans ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚° ---------------------------------------------
    vectors_norm = normalize(vectors)
    kmeans = KMeans(n_clusters=num_clusters, random_state=42)
    labels = kmeans.fit_predict(vectors_norm)
    df["ã‚¯ãƒ©ã‚¹ã‚¿"] = labels

    st.success(
        f"âœ… {num_clusters} ã‚¯ãƒ©ã‚¹ã‚¿ã«åˆ†é¡ã—ã¾ã—ãŸã€‚å„ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã«è¦ç´„ã¨å›ç­”ã‚’ç”Ÿæˆã§ãã¾ã™ã€‚"
    )

    # ----------------------------------------------------------------------
    # ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã® UI
    # ----------------------------------------------------------------------
    for cluster_id in range(num_clusters):
        cluster_df = df[df["ã‚¯ãƒ©ã‚¹ã‚¿"] == cluster_id]
        cluster_questions = cluster_df["è³ªå•"].tolist()

        with st.expander(f"â–¶ï¸ ã‚¯ãƒ©ã‚¹ã‚¿ {cluster_id}ï¼š{len(cluster_questions)} ä»¶ã®è³ªå•"):
            summary_key = f"summary_question_{cluster_id}"
            answer_key = f"model_answer_{cluster_id}"

            # â”€â”€ æ—¢å­˜ã®ä»£è¡¨è³ªå•ãƒ»æ¨¡ç¯„å›ç­”ã‚’è¡¨ç¤º â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if summary_key in st.session_state and st.session_state[summary_key]:
                st.markdown(
                    f"""**ğŸ’¬ ä»£è¡¨è³ªå•ï¼š**

{st.session_state[summary_key]}"""
                )

            if answer_key in st.session_state and st.session_state[answer_key]:
                st.markdown(
                    f"""**ğŸ“ æ¨¡ç¯„å›ç­”ï¼š**

{st.session_state[answer_key]}"""
                )

            # è³ªå•ãƒªã‚¹ãƒˆã‚’åˆ—æŒ™
            st.markdown("\n".join([f"- {q}" for q in cluster_questions]))

            # â”€â”€ GPT ã§ä»£è¡¨è³ªå•ç”Ÿæˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if st.button(
                f"ğŸ§  ã‚¯ãƒ©ã‚¹ã‚¿ {cluster_id} ã®ä»£è¡¨è³ªå•ã‚’ç”Ÿæˆ",
                key=f"summary_button_{cluster_id}",
            ):
                prompt = (
                    "ä»¥ä¸‹ã®è³ªå•ã¯è¬›ç¾©ä¸­ã«å—ã‘ãŸä¼¼ãŸå†…å®¹ã®è³ªå•ã§ã™ã€‚"
                    "ã“ã‚Œã‚‰ã‚’è¦ç´„ã—ã¦ã€ä»£è¡¨çš„ãª1ã¤ã®è³ªå•ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\n"
                    "è³ªå•ä¸€è¦§ï¼š\n"
                )
                prompt += "\n".join([f"- {q}" for q in cluster_questions])
                prompt += "\n\nä»£è¡¨è³ªå•ï¼š"

                with st.spinner("GPT ãŒä»£è¡¨è³ªå•ã‚’è¦ç´„ä¸­..."):
                    try:
                        response = client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {
                                    "role": "system",
                                    "content": "ã‚ãªãŸã¯è¦ªåˆ‡ã§è¦ç´„ãŒä¸Šæ‰‹ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚",
                                },
                                {"role": "user", "content": prompt},
                            ],
                            temperature=0.5,
                        )
                        summary_question = response.choices[0].message.content.strip()
                        st.session_state[summary_key] = summary_question
                        st.session_state[answer_key] = ""  # å…ˆã«å›ç­”ã‚’ã‚¯ãƒªã‚¢
                    except Exception as e:
                        st.error(f"ä»£è¡¨è³ªå•ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

            # â”€â”€ GPT ã§æ¨¡ç¯„å›ç­”ç”Ÿæˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if st.button(
                f"ğŸ’¡ ã‚¯ãƒ©ã‚¹ã‚¿ {cluster_id} ã®æ¨¡ç¯„å›ç­”ã‚’ç”Ÿæˆ",
                key=f"answer_button_{cluster_id}",
            ):
                summary_question = st.session_state.get(summary_key)
                if not summary_question:
                    st.error("å…ˆã«ä»£è¡¨è³ªå•ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚")
                    st.stop()

                answer_prompt = (
                    "ä»¥ä¸‹ã®è³ªå•ã«å¯¾ã—ã¦ã€è¬›ç¾©ã§ä½¿ãˆã‚‹æ¨¡ç¯„çš„ãªå›ç­”ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚\n\n"
                    f"è³ªå•ï¼š{summary_question}\n\nå›ç­”ï¼š"
                )

                with st.spinner("GPT ãŒæ¨¡ç¯„å›ç­”ã‚’ç”Ÿæˆä¸­..."):
                    try:
                        answer_response = client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {
                                    "role": "system",
                                    "content": "ã‚ãªãŸã¯è¦ªåˆ‡ã§ã‚ã‹ã‚Šã‚„ã™ãèª¬æ˜ã§ãã‚‹è¬›ç¾©ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚",
                                },
                                {"role": "user", "content": answer_prompt},
                            ],
                            temperature=0.7,
                        )
                        model_answer = answer_response.choices[
                            0
                        ].message.content.strip()
                        st.session_state[answer_key] = model_answer
                    except Exception as e:
                        st.error(f"æ¨¡ç¯„å›ç­”ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
